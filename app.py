import streamlit as st
import pandas as pd
import joblib
import os
import shap
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯

# å¯¼å…¥é…ç½®å’Œæ ¸å¿ƒæ¨¡å—
from config import PATHS, FILES
from src.repair_module import AnomalyRepairer
from src.utils import (
    load_system_state,
    predict_with_threshold,
    process_and_train,
    save_system_state,
)

# è®¾ç½® matplotlib æ ·å¼
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = 'white'

# ==========================================
# 1. é¡µé¢é…ç½®ä¸çŠ¶æ€åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="Mixed-Type Anomaly Detection System", layout="wide")

# --- ã€å…³é”®ä¿®æ”¹ã€‘åˆå§‹åŒ– Session State (è®°å¿†æ¨¡å—) ---
# å¦‚æœç³»ç»Ÿç¬¬ä¸€æ¬¡å¯åŠ¨ï¼Œå…ˆåœ¨å†…å­˜é‡Œå»ºå‡ ä¸ª"ç©ºæŠ½å±‰"æ¥æ”¾æ•°æ®
if 'uploaded_df' not in st.session_state:
    st.session_state.uploaded_df = None  # å­˜æ”¾ä¸Šä¼ çš„æ•°æ®
if 'train_metrics' not in st.session_state:
    st.session_state.train_metrics = None # å­˜æ”¾è®­ç»ƒåˆ†æ•°
if 'is_trained' not in st.session_state:
    st.session_state.is_trained = False   # è®°å½•æ˜¯å¦è®­ç»ƒè¿‡

# Sidebar å¯¼èˆª
st.sidebar.title("ğŸ“Œ Navigation")
page = st.sidebar.radio("Go to", ["1. Data & Model Training", "2. Detection & Repair"])

# =========================================================
# é¡µé¢ 1: æ•°æ®ä¸Šä¼ ä¸è®­ç»ƒ
# =========================================================
if page == "1. Data & Model Training":
    st.title("ğŸ› ï¸ System Setup: Data Import & Training")
    st.markdown("Upload your mixed-type dataset (CSV) to build the anomaly detection model.")
    
    # 1. æ–‡ä»¶ä¸Šä¼ 
    # æ³¨æ„ï¼šåˆ‡æ¢é¡µé¢å file_uploader æ§ä»¶æœ¬èº«ä¼šé‡ç½®ï¼Œè¿™æ˜¯ Streamlit çš„ç‰¹æ€§
    # ä½†æˆ‘ä»¬æŠŠè¯»å–åçš„æ•°æ®å­˜åˆ°äº† session_state é‡Œï¼Œæ‰€ä»¥æ•°æ®ä¸ä¼šä¸¢
    uploaded_file = st.file_uploader("Upload CSV File", type=["csv"])
    
    # å¦‚æœç”¨æˆ·åˆšä¸Šä¼ äº†æ–°æ–‡ä»¶
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.session_state.uploaded_df = df  # ã€å­˜å…¥è®°å¿†ã€‘
            # å¦‚æœä¸Šä¼ äº†æ–°æ–‡ä»¶ï¼Œé‡ç½®è®­ç»ƒçŠ¶æ€
            st.session_state.is_trained = False 
            st.session_state.train_metrics = None
        except Exception as e:
            st.error(f"Error reading file: {e}")

    # 2. æ£€æŸ¥è®°å¿†ä¸­æ˜¯å¦æœ‰æ•°æ®
    if st.session_state.uploaded_df is not None:
        df = st.session_state.uploaded_df
        st.success(f"Dataset Loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        st.dataframe(df.head())
        
        # =========================================================
        # ğŸ“Š æ•°æ®ç»Ÿè®¡é¢æ¿
        # =========================================================
        with st.expander("ğŸ“Š Data Statistics & Quality Report", expanded=False):
            # --- åŸºç¡€ä¿¡æ¯ ---
            st.markdown("#### ğŸ“‹ Basic Information")
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("Total Rows", f"{df.shape[0]:,}")
            col2.metric("Total Columns", df.shape[1])
            col3.metric("Missing Values", f"{df.isnull().sum().sum():,}")
            col4.metric("Memory Usage", f"{df.memory_usage(deep=True).sum() / 1024:.1f} KB")
            
            st.markdown("---")
            
            # --- æ•°æ®ç±»å‹åˆ†å¸ƒ ---
            st.markdown("#### ğŸ·ï¸ Data Types Distribution")
            dtype_counts = df.dtypes.astype(str).value_counts()
            col_type1, col_type2 = st.columns(2)
            
            with col_type1:
                # æ•°å€¼å‹åˆ—
                numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
                st.markdown(f"**Numeric Columns** ({len(numeric_cols)})")
                if numeric_cols:
                    st.write(", ".join(numeric_cols))
                else:
                    st.write("None")
            
            with col_type2:
                # åˆ†ç±»å‹åˆ—
                cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
                st.markdown(f"**Categorical Columns** ({len(cat_cols)})")
                if cat_cols:
                    st.write(", ".join(cat_cols))
                else:
                    st.write("None")
            
            st.markdown("---")
            
            # --- ç¼ºå¤±å€¼åˆ†æ ---
            st.markdown("#### â“ Missing Values Analysis")
            missing_data = df.isnull().sum()
            missing_data = missing_data[missing_data > 0].sort_values(ascending=False)
            
            if len(missing_data) > 0:
                missing_df = pd.DataFrame({
                    'Column': missing_data.index,
                    'Missing Count': missing_data.values,
                    'Missing %': (missing_data.values / len(df) * 100).round(2)
                })
                st.dataframe(missing_df, use_container_width=True, hide_index=True)
            else:
                st.success("âœ… No missing values found!")
            
            st.markdown("---")
            
            # --- æ•°å€¼ç‰¹å¾ç»Ÿè®¡ ---
            if numeric_cols:
                st.markdown("#### ğŸ“ˆ Numeric Features Statistics")
                st.dataframe(df[numeric_cols].describe().T.round(2), use_container_width=True)
            
            # --- åˆ†ç±»ç‰¹å¾åˆ†å¸ƒ ---
            if cat_cols:
                st.markdown("#### ğŸ“Š Categorical Features Distribution")
                selected_cat = st.selectbox("Select a categorical column to view distribution:", cat_cols)
                if selected_cat:
                    value_counts = df[selected_cat].value_counts()
                    dist_df = pd.DataFrame({
                        'Value': value_counts.index,
                        'Count': value_counts.values,
                        'Percentage': (value_counts.values / len(df) * 100).round(2)
                    })
                    st.dataframe(dist_df, use_container_width=True, hide_index=True)
        
        # é€‰æ‹©ç›®æ ‡åˆ—
        target_col = st.selectbox("Select the Target Column (Label)", df.columns, index=len(df.columns)-1)
        
        # --- ç›®æ ‡åˆ—åˆ†å¸ƒé¢„è§ˆ ---
        if target_col:
            target_counts = df[target_col].value_counts()
            col_t1, col_t2, col_t3 = st.columns(3)
            
            total = len(df)
            normal_count = target_counts.get(0, 0)
            anomaly_count = target_counts.get(1, 0)
            
            col_t1.metric("Normal (0)", f"{normal_count:,}", f"{normal_count/total*100:.1f}%")
            col_t2.metric("Anomaly (1)", f"{anomaly_count:,}", f"{anomaly_count/total*100:.1f}%")
            col_t3.metric("Imbalance Ratio", f"1:{normal_count//max(anomaly_count,1)}" if anomaly_count > 0 else "N/A")
            
            st.info(f"The system will learn to detect anomalies based on '{target_col}'. (0=Normal, 1=Anomaly)")
        
        # 3. è®­ç»ƒæŒ‰é’®
        if st.button("ğŸš€ Start Training Model"):
            with st.spinner('Training LightGBM model and preparing repair database...'):
                # è°ƒç”¨ utils
                model, X_test, normal_data, metrics, feats = process_and_train(df, target_col)
                
                # ä¿å­˜åˆ°ç¡¬ç›˜ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼‰
                save_system_state(model, X_test, normal_data, feats)
                
                # ã€å­˜å…¥è®°å¿†ã€‘
                st.session_state.train_metrics = metrics
                st.session_state.is_trained = True
                
            st.success("âœ… Training Complete!")
            st.balloons()

    # 4. æ˜¾ç¤ºè®­ç»ƒç»“æœ (å³ä½¿åˆ·æ–°é¡µé¢ï¼Œåªè¦ session_state é‡Œæœ‰ï¼Œå°±æ˜¾ç¤º)
    if st.session_state.is_trained and st.session_state.train_metrics is not None:
        metrics = st.session_state.train_metrics
        
        st.markdown("---")
        st.subheader("ğŸ“Š Model Performance")
        
        # æŒ‡æ ‡å¡ç‰‡ - 5ä¸ªæ ¸å¿ƒæŒ‡æ ‡
        col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)
        col_m1.metric("Accuracy", f"{metrics.get('accuracy', 0):.4f}")
        col_m2.metric("Precision", f"{metrics.get('precision', 0):.4f}")
        col_m3.metric("Recall", f"{metrics.get('recall', 0):.4f}")
        col_m4.metric("F1-Score", f"{metrics['f1']:.4f}")
        col_m5.metric("AUC-ROC", f"{metrics['auc']:.4f}")
        
        st.markdown("---")
        
        # =========================================================
        # ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨åŒºåŸŸ
        # =========================================================
        st.subheader("ğŸ“ˆ Visual Analytics")
        
        viz_tab1, viz_tab2, viz_tab3 = st.tabs(["ğŸ¯ ROC Curve", "ğŸ“Š Confusion Matrix", "â­ Feature Importance"])
        
        # ---------------------------------------------------------
        # ROC æ›²çº¿
        # ---------------------------------------------------------
        with viz_tab1:
            if "roc_curve" in metrics:
                fig_roc, ax_roc = plt.subplots(figsize=(8, 6))
                
                fpr = metrics["roc_curve"]["fpr"]
                tpr = metrics["roc_curve"]["tpr"]
                auc_score = metrics["auc"]
                
                # ç»˜åˆ¶ ROC æ›²çº¿
                ax_roc.plot(fpr, tpr, color='#3498db', lw=2.5, 
                           label=f'ROC Curve (AUC = {auc_score:.4f})')
                ax_roc.plot([0, 1], [0, 1], color='#95a5a6', lw=1.5, 
                           linestyle='--', label='Random Classifier')
                
                # å¡«å…… AUC åŒºåŸŸ
                ax_roc.fill_between(fpr, tpr, alpha=0.2, color='#3498db')
                
                ax_roc.set_xlim([0.0, 1.0])
                ax_roc.set_ylim([0.0, 1.05])
                ax_roc.set_xlabel('False Positive Rate', fontsize=12)
                ax_roc.set_ylabel('True Positive Rate', fontsize=12)
                ax_roc.set_title('Receiver Operating Characteristic (ROC) Curve', fontsize=14, fontweight='bold')
                ax_roc.legend(loc='lower right', fontsize=10)
                ax_roc.grid(True, alpha=0.3)
                
                plt.tight_layout()
                st.pyplot(fig_roc)
                plt.close(fig_roc)
            else:
                st.info("ROC curve is only available for binary classification.")
        
        # ---------------------------------------------------------
        # æ··æ·†çŸ©é˜µ
        # ---------------------------------------------------------
        with viz_tab2:
            if "confusion_matrix" in metrics:
                cm = metrics["confusion_matrix"]
                
                fig_cm, ax_cm = plt.subplots(figsize=(8, 6))
                
                # ä½¿ç”¨ imshow ç»˜åˆ¶çƒ­åŠ›å›¾
                im = ax_cm.imshow(cm, interpolation='nearest', cmap='Blues')
                
                # æ·»åŠ é¢œè‰²æ¡
                cbar = ax_cm.figure.colorbar(im, ax=ax_cm)
                cbar.ax.set_ylabel('Count', rotation=-90, va="bottom", fontsize=11)
                
                # è®¾ç½®æ ‡ç­¾
                classes = ['Normal (0)', 'Anomaly (1)']
                ax_cm.set(xticks=np.arange(cm.shape[1]),
                         yticks=np.arange(cm.shape[0]),
                         xticklabels=classes, yticklabels=classes,
                         ylabel='Actual Label',
                         xlabel='Predicted Label')
                
                ax_cm.set_title('Confusion Matrix', fontsize=14, fontweight='bold')
                
                # åœ¨æ¯ä¸ªæ ¼å­ä¸­æ˜¾ç¤ºæ•°å€¼
                thresh = cm.max() / 2.
                for i in range(cm.shape[0]):
                    for j in range(cm.shape[1]):
                        ax_cm.text(j, i, format(cm[i, j], 'd'),
                                  ha="center", va="center",
                                  color="white" if cm[i, j] > thresh else "black",
                                  fontsize=20, fontweight='bold')
                
                plt.tight_layout()
                st.pyplot(fig_cm)
                plt.close(fig_cm)
                
                # æ˜¾ç¤ºæ··æ·†çŸ©é˜µè§£è¯»
                tn, fp, fn, tp = cm.ravel()
                col_cm1, col_cm2, col_cm3, col_cm4 = st.columns(4)
                col_cm1.metric("True Negative", tn, help="Correctly predicted as Normal")
                col_cm2.metric("False Positive", fp, help="Normal misclassified as Anomaly")
                col_cm3.metric("False Negative", fn, help="Anomaly misclassified as Normal")
                col_cm4.metric("True Positive", tp, help="Correctly predicted as Anomaly")
        
        # ---------------------------------------------------------
        # ç‰¹å¾é‡è¦æ€§
        # ---------------------------------------------------------
        with viz_tab3:
            if "feature_importance" in metrics:
                importance = metrics["feature_importance"]
                
                # æ’åº
                sorted_importance = dict(sorted(importance.items(), 
                                                key=lambda x: x[1], reverse=True))
                
                fig_fi, ax_fi = plt.subplots(figsize=(10, max(6, len(importance) * 0.4)))
                
                features = list(sorted_importance.keys())
                values = list(sorted_importance.values())
                
                # ä½¿ç”¨æ¸å˜è‰²
                colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(features)))[::-1]
                
                bars = ax_fi.barh(features[::-1], values[::-1], color=colors)
                
                ax_fi.set_xlabel('Importance Score', fontsize=12)
                ax_fi.set_title('Feature Importance (LightGBM)', fontsize=14, fontweight='bold')
                ax_fi.grid(True, axis='x', alpha=0.3)
                
                # åœ¨æ¡å½¢ä¸Šæ˜¾ç¤ºæ•°å€¼
                for bar, val in zip(bars, values[::-1]):
                    ax_fi.text(bar.get_width() + max(values) * 0.01, bar.get_y() + bar.get_height()/2,
                              f'{val:.0f}', va='center', fontsize=9)
                
                plt.tight_layout()
                st.pyplot(fig_fi)
                plt.close(fig_fi)
                
                # æ˜¾ç¤º Top 5 ç‰¹å¾
                st.markdown("#### ğŸ† Top 5 Most Important Features")
                top5 = list(sorted_importance.items())[:5]
                top5_df = pd.DataFrame(top5, columns=['Feature', 'Importance'])
                top5_df['Rank'] = range(1, len(top5_df) + 1)
                top5_df = top5_df[['Rank', 'Feature', 'Importance']]
                st.dataframe(top5_df, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        st.markdown("ğŸ‘‰ **Now go to '2. Detection & Repair' page to test the system.**")

# =========================================================
# é¡µé¢ 2: æ£€æµ‹ä¸ä¿®å¤
# =========================================================
elif page == "2. Detection & Repair":
    st.title("ğŸ” Interactive Detection & Repair")
    
    # æ£€æŸ¥ç¡¬ç›˜ä¸Šæœ‰æ²¡æœ‰æ¨¡å‹æ–‡ä»¶ (è¿™æ˜¯ä¸ºäº†é˜²æ­¢ç”¨æˆ·ç›´æ¥è·³åˆ°è¿™ä¸€é¡µ)
    if not os.path.exists(FILES["model"]):
        st.warning("âš ï¸ No model found. Please go to 'Data & Model Training' page first.")
        st.stop()
        
    # åŠ è½½æ¨¡å‹ (ä½¿ç”¨ cache_resource é¿å…é‡å¤åŠ è½½)
    @st.cache_resource
    def load_model_resources():
        return load_system_state()

    model, X_test, normal_data = load_model_resources()
    
    # âš¡ SHAP Explainer ç¼“å­˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
    # TreeExplainer åˆ›å»ºå¼€é”€å¤§ï¼Œç¼“å­˜ååªåˆ›å»ºä¸€æ¬¡
    @st.cache_resource
    def get_shap_explainer(_model):
        """ç¼“å­˜ SHAP explainerï¼Œé¿å…é‡å¤åˆ›å»º"""
        return shap.TreeExplainer(_model)
    
    explainer = get_shap_explainer(model)
    
    # åˆå§‹åŒ–ä¿®å¤å™¨
    if 'repairer' not in st.session_state:
        st.session_state.repairer = AnomalyRepairer(normal_data)
        
    # é˜²æ­¢ç´¢å¼•æŠ¥é”™
    max_len = len(X_test) - 1
    if max_len < 0: max_len = 0
    
    # =========================================================
    # ä½¿ç”¨ Tabs åŒºåˆ†å•æ¡æ£€æµ‹å’Œæ‰¹é‡æ£€æµ‹
    # =========================================================
    tab1, tab2 = st.tabs(["ğŸ”¬ Single Detection", "ğŸ“Š Batch Detection & Export"])
    
    # ---------------------------------------------------------
    # Tab 1: å•æ¡æ£€æµ‹
    # ---------------------------------------------------------
    with tab1:
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸ”¬ Single Detection")
        
        sample_id = st.sidebar.number_input(
            "Enter Test Sample ID", 
            min_value=0, 
            max_value=max_len, 
            value=0, 
            step=1,
            help=f"Valid range: 0 to {max_len}"
        )
        
        try:
            sample_data = X_test.iloc[[sample_id]]
            
            c1, c2 = st.columns([1, 2])
            with c1:
                st.subheader("Target Profile")
                st.dataframe(sample_data.T, height=400)
                
            with c2:
                st.subheader("Analysis Result")
                if st.button("Run Diagnosis", key="run_diag"):
                    pred_arr, prob_arr = predict_with_threshold(model, sample_data)
                    pred = int(pred_arr[0])
                    prob = float(prob_arr[0])
                    
                    if pred == 1:
                        st.error(f"ğŸš¨ ANOMALY DETECTED (Risk Score: {prob:.4f})")
                        
                        # SHAP è§£é‡Šï¼ˆä½¿ç”¨ç¼“å­˜çš„ explainerï¼‰
                        shap_values = explainer.shap_values(sample_data)
                        vals = shap_values[1][0] if isinstance(shap_values, list) else shap_values[0]
                        
                        top_indices = np.argsort(vals)[::-1][:3]
                        feat_names = sample_data.columns
                        
                        st.markdown("### ğŸ› ï¸ Smart Repair Suggestions")
                        
                        # æ”¶é›†ä¿®å¤å»ºè®®
                        repair_suggestions = {}
                        for idx in top_indices:
                            if vals[idx] > 0:
                                fname = feat_names[idx]
                                report, _ = st.session_state.repairer.generate_repair_suggestion(sample_data, fname)
                                repair_suggestions[fname] = {
                                    'current': sample_data[fname].values[0],
                                    'suggested': report['Suggested Value'],
                                    'impact': vals[idx],
                                    'logic': report['Repair Logic']
                                }
                                
                                with st.expander(f"ğŸ”´ Issue: {fname} (Impact: +{vals[idx]:.2f})", expanded=True):
                                    st.write(f"**Current:** {sample_data[fname].values[0]}")
                                    st.success(f"**Suggested:** {report['Suggested Value']}")
                                    st.caption(f"Reasoning: {report['Repair Logic']}")
                        
                        # ä¿å­˜åŸå§‹æ•°æ®å’Œä¿®å¤å»ºè®®åˆ° session_state
                        st.session_state.current_sample = sample_data.copy()
                        st.session_state.repair_suggestions = repair_suggestions
                        st.session_state.original_prob = prob
                        
                    else:
                        st.success(f"âœ… Normal Profile (Risk Score: {prob:.4f})")
                        # æ¸…é™¤ä¹‹å‰çš„ä¿®å¤çŠ¶æ€
                        if 'repair_suggestions' in st.session_state:
                            del st.session_state.repair_suggestions
                
                # =========================================================
                # ğŸ”„ ä¿®å¤éªŒè¯åŠŸèƒ½
                # =========================================================
                if 'repair_suggestions' in st.session_state and st.session_state.repair_suggestions:
                    st.markdown("---")
                    st.markdown("### ğŸ”„ Repair Verification")
                    st.info("Apply the suggested repairs and verify if the sample becomes normal.")
                    
                    if st.button("âœ¨ Apply All Repairs & Verify", key="apply_repairs", type="primary"):
                        # åˆ›å»ºä¿®å¤åçš„æ•°æ®å‰¯æœ¬
                        repaired_data = st.session_state.current_sample.copy()
                        
                        # åº”ç”¨æ‰€æœ‰ä¿®å¤å»ºè®®
                        for fname, repair_info in st.session_state.repair_suggestions.items():
                            repaired_data[fname] = repair_info['suggested']
                        
                        # é‡æ–°é¢„æµ‹
                        new_pred_arr, new_prob_arr = predict_with_threshold(model, repaired_data)
                        new_pred = int(new_pred_arr[0])
                        new_prob = float(new_prob_arr[0])
                        original_prob = st.session_state.original_prob
                        
                        # æ˜¾ç¤ºä¿®å¤å‰åå¯¹æ¯”
                        st.markdown("#### ğŸ“Š Before vs After Comparison")
                        
                        comparison_data = []
                        for fname, repair_info in st.session_state.repair_suggestions.items():
                            comparison_data.append({
                                'Feature': fname,
                                'Before': repair_info['current'],
                                'After': repair_info['suggested'],
                                'Impact': f"+{repair_info['impact']:.2f}"
                            })
                        
                        comparison_df = pd.DataFrame(comparison_data)
                        st.dataframe(comparison_df, use_container_width=True, hide_index=True)
                        
                        # æ˜¾ç¤ºé¢„æµ‹ç»“æœå¯¹æ¯”
                        st.markdown("#### ğŸ¯ Prediction Result")
                        col_before, col_after, col_change = st.columns(3)
                        
                        with col_before:
                            st.metric(
                                "Before Repair",
                                "ğŸš¨ Anomaly",
                                f"Risk: {original_prob:.4f}"
                            )
                        
                        with col_after:
                            if new_pred == 0:
                                st.metric(
                                    "After Repair",
                                    "âœ… Normal",
                                    f"Risk: {new_prob:.4f}"
                                )
                            else:
                                st.metric(
                                    "After Repair",
                                    "ğŸš¨ Still Anomaly",
                                    f"Risk: {new_prob:.4f}"
                                )
                        
                        with col_change:
                            risk_change = new_prob - original_prob
                            st.metric(
                                "Risk Change",
                                f"{risk_change:+.4f}",
                                f"{risk_change/original_prob*100:+.1f}%" if original_prob > 0 else "N/A",
                                delta_color="inverse"
                            )
                        
                        # éªŒè¯ç»“æœ
                        if new_pred == 0:
                            st.success("ğŸ‰ **Repair Successful!** The sample is now classified as Normal.")
                            st.balloons()
                        else:
                            st.warning("âš ï¸ **Partial Improvement.** The sample is still classified as Anomaly, but risk score decreased. Consider additional repairs.")
        except Exception as e:
            st.error(f"Error analyzing sample: {e}")
    
    # ---------------------------------------------------------
    # Tab 2: æ‰¹é‡æ£€æµ‹ + å¯¼å‡º
    # ---------------------------------------------------------
    with tab2:
        st.markdown("### ğŸ“Š Batch Anomaly Detection")
        st.markdown("Scan multiple samples at once and export results to CSV.")
        
        # é€‰æ‹©æ£€æµ‹èŒƒå›´
        col_range1, col_range2 = st.columns(2)
        with col_range1:
            detection_mode = st.radio(
                "Detection Scope",
                ["All Test Samples", "Custom Range"],
                horizontal=True
            )
        
        if detection_mode == "Custom Range":
            with col_range2:
                range_start = st.number_input("Start Index", min_value=0, max_value=max_len, value=0)
                range_end = st.number_input("End Index", min_value=0, max_value=max_len, value=min(100, max_len))
        else:
            range_start, range_end = 0, max_len
        
        # æ‰¹é‡æ£€æµ‹æŒ‰é’®
        if st.button("ğŸš€ Run Batch Detection", key="batch_detect", type="primary"):
            with st.spinner(f"Scanning samples {range_start} to {range_end}..."):
                # è·å–æŒ‡å®šèŒƒå›´çš„æ•°æ®
                batch_data = X_test.iloc[range_start:range_end+1]
                
                # æ‰¹é‡é¢„æµ‹
                predictions, probabilities = predict_with_threshold(model, batch_data)
                
                # æ„å»ºç»“æœ DataFrame
                results_df = batch_data.copy()
                results_df.insert(0, 'Sample_ID', range(range_start, range_end+1))
                results_df['Prediction'] = predictions
                results_df['Risk_Score'] = probabilities.round(4)
                results_df['Status'] = np.where(predictions == 1, 'ğŸš¨ Anomaly', 'âœ… Normal')
                
                # ä¿å­˜åˆ° session_state
                st.session_state.batch_results = results_df
                st.session_state.batch_stats = {
                    'total': len(results_df),
                    'anomalies': int((predictions == 1).sum()),
                    'normals': int((predictions == 0).sum())
                }
            
            st.success("âœ… Batch detection complete!")
        
        # æ˜¾ç¤ºç»“æœ
        if 'batch_results' in st.session_state and st.session_state.batch_results is not None:
            stats = st.session_state.batch_stats
            results_df = st.session_state.batch_results
            
            # ç»Ÿè®¡æŒ‡æ ‡
            st.markdown("---")
            st.markdown("### ğŸ“ˆ Detection Summary")
            col_s1, col_s2, col_s3, col_s4 = st.columns(4)
            col_s1.metric("Total Scanned", f"{stats['total']:,}")
            col_s2.metric("Anomalies Found", f"{stats['anomalies']:,}", 
                         delta=f"{stats['anomalies']/stats['total']*100:.1f}%", delta_color="inverse")
            col_s3.metric("Normal Samples", f"{stats['normals']:,}")
            col_s4.metric("Anomaly Rate", f"{stats['anomalies']/stats['total']*100:.2f}%")
            
            st.markdown("---")
            
            # ç­›é€‰é€‰é¡¹
            filter_option = st.radio(
                "Filter Results",
                ["All", "Anomalies Only", "Normal Only"],
                horizontal=True
            )
            
            if filter_option == "Anomalies Only":
                display_df = results_df[results_df['Prediction'] == 1]
            elif filter_option == "Normal Only":
                display_df = results_df[results_df['Prediction'] == 0]
            else:
                display_df = results_df
            
            # æ˜¾ç¤ºç»“æœè¡¨æ ¼
            st.markdown(f"### ğŸ“‹ Results ({len(display_df)} samples)")
            st.dataframe(
                display_df[['Sample_ID', 'Status', 'Risk_Score'] + list(X_test.columns)],
                use_container_width=True,
                height=400
            )
            
            st.markdown("---")
            
            # å¯¼å‡ºåŠŸèƒ½
            st.markdown("### ğŸ“¥ Export Results")
            col_exp1, col_exp2 = st.columns(2)
            
            with col_exp1:
                # å¯¼å‡ºå…¨éƒ¨ç»“æœ
                csv_all = results_df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ Download All Results (CSV)",
                    data=csv_all,
                    file_name="batch_detection_all.csv",
                    mime="text/csv",
                    key="download_all"
                )
            
            with col_exp2:
                # åªå¯¼å‡ºå¼‚å¸¸
                anomalies_df = results_df[results_df['Prediction'] == 1]
                if len(anomalies_df) > 0:
                    csv_anomalies = anomalies_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="ğŸš¨ Download Anomalies Only (CSV)",
                        data=csv_anomalies,
                        file_name="batch_detection_anomalies.csv",
                        mime="text/csv",
                        key="download_anomalies"
                    )
                else:
                    st.info("No anomalies found to export.")
