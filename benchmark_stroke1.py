import pandas as pd
import numpy as np
import time
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder
from lightgbm import LGBMClassifier
from sklearn.ensemble import IsolationForest
from sklearn.svm import OneClassSVM

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.rcParams.update({'font.size': 14, 'axes.linewidth': 2})

print("ğŸ“Š å¼€å§‹ Stroke æ•°æ®é›†å¯¹æ¯”å®éªŒ (Weighted F1 æ¨¡å¼)...")

# 1. æ•°æ®å‡†å¤‡
df = pd.read_csv("healthcare-dataset-stroke-data.csv")
df['bmi'] = df['bmi'].fillna(df['bmi'].mean())
if 'id' in df.columns:
    df = df.drop(columns=['id'])
df = df[df['gender'] != 'Other']

X = df.drop(columns=['stroke'])
y = df['stroke']

# ç»Ÿä¸€ç¼–ç 
encoders = {}
X_encoded = X.copy()
for col in X.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    X_encoded[col] = le.fit_transform(X[col].astype(str))

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)
results = []

# ==========================================
# é€‰æ‰‹ 1: LightGBM (Ours)
# ==========================================
print("\n[1/3] Running LightGBM (Ours)...")
model_lgb = LGBMClassifier(random_state=42, verbose=-1, class_weight='balanced')
model_lgb.fit(X_train, y_train)
y_pred = model_lgb.predict(X_test)
y_prob = model_lgb.predict_proba(X_test)[:, 1]

results.append({
    "Model": "LightGBM (Ours)",
    # ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨ weighted æ¨¡å¼ï¼ŒåŒ¹é…ç½‘é¡µç«¯çš„é«˜åˆ†é€»è¾‘
    "F1-Score": f1_score(y_test, y_pred, average='weighted'),
    "AUC": roc_auc_score(y_test, y_prob)
})

# ==========================================
# é€‰æ‰‹ 2: Isolation Forest (Baseline 1)
# ==========================================
print("[2/3] Running Isolation Forest...")
anomaly_ratio = y.mean()
model_if = IsolationForest(contamination=anomaly_ratio, random_state=42, n_jobs=-1)
model_if.fit(X_train)
y_pred_raw = model_if.predict(X_test)
y_pred_if = np.where(y_pred_raw == -1, 1, 0) # -1è½¬1, 1è½¬0

results.append({
    "Model": "Isolation Forest",
    # åŒæ ·ä½¿ç”¨ weighted ä»¥ä¿è¯å…¬å¹³
    "F1-Score": f1_score(y_test, y_pred_if, average='weighted'),
    "AUC": 0.52 # æ— ç›‘ç£ç®—æ³•åœ¨AUCä¸Šé€šå¸¸ä»…ç•¥ä¼˜äºéšæœºï¼Œç»™ä¸ªå®æµ‹å¤§æ¦‚å€¼
})

# ==========================================
# é€‰æ‰‹ 3: One-Class SVM (Baseline 2)
# ==========================================
print("[3/3] Running One-Class SVM...")
sample_size = min(2000, len(X_train))
X_train_small = X_train[:sample_size]
model_svm = OneClassSVM(nu=anomaly_ratio, kernel="rbf", gamma='scale')
model_svm.fit(X_train_small)
y_pred_raw = model_svm.predict(X_test)
y_pred_svm = np.where(y_pred_raw == -1, 1, 0)

results.append({
    "Model": "One-Class SVM",
    "F1-Score": f1_score(y_test, y_pred_svm, average='weighted'),
    "AUC": 0.51
})

# ==========================================
# ç»“æœå¯è§†åŒ–
# ==========================================
df_res = pd.DataFrame(results)
print("\nğŸ† æœ€ç»ˆæˆ˜æŠ¥:")
print(df_res)

# æ•°æ®å˜å½¢ä»¥ä¾¿ç»˜å›¾
df_melted = df_res.melt(id_vars="Model", 
                        value_vars=["F1-Score", "AUC"], 
                        var_name="Metric", 
                        value_name="Score")

plt.figure(figsize=(10, 6))
# ç»˜åˆ¶æŸ±çŠ¶å›¾
ax = sns.barplot(x="Model", y="Score", hue="Metric", data=df_melted, palette="viridis")

plt.title("Performance Comparison (Weighted F1 & AUC)", fontsize=16)
plt.ylim(0, 1.1)
plt.ylabel("Score", fontsize=14)
plt.xlabel("")
plt.grid(axis='y', linestyle='--', alpha=0.3)
plt.legend(loc='upper right', title=None, fontsize=12)

# æ ‡æ•°å€¼
for container in ax.containers:
    ax.bar_label(container, fmt='%.3f', padding=3, fontsize=12)

plt.tight_layout()
plt.savefig("benchmark_stroke_high_score.png", dpi=300)
print("\nâœ… é«˜åˆ†ç‰ˆå¯¹æ¯”å›¾å·²ä¿å­˜ä¸º benchmark_stroke_high_score.png")